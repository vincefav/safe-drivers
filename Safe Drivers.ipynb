{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "combi = pd.concat([train.drop('target', axis=1), test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Unnecessary\n",
    "\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# for i in combi.select_dtypes(exclude=[np.number]).columns:\n",
    "#     lbl = LabelEncoder()\n",
    "#     lbl.fit(combi[i])\n",
    "#     train[i] = lbl.transform(train[i])\n",
    "#     test[i] = lbl.transform(test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Too much data for my computer, so we'll take a sample\n",
    "train = train.sample(frac=1.0)\n",
    "train_sample = train.sample(20000)\n",
    "\n",
    "train_sample = train_sample.head(10000)\n",
    "test = train_sample.tail(10000)\n",
    "\n",
    "x = train_sample.drop('target', axis=1)\n",
    "y = train_sample['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=2, min_child_weight=1, missing=None, n_estimators=107,\n",
      "       n_jobs=1, nthread=1, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1.3999999999999999, scale_pos_weight=1,\n",
      "       seed=0, silent=True, subsample=1) \n",
      "\n",
      "Mean score: 0.610121851248\n",
      "Std Dev:    0.00829439515399\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "kf = KFold(n_splits=3, shuffle=True)\n",
    "\n",
    "clf = XGBClassifier()\n",
    "params = {'max_depth': [2],\n",
    "         'n_estimators': np.arange(80,130,1),\n",
    "         'reg_lambda': np.arange(1.4, 1.61, .1)}\n",
    "\n",
    "grid = GridSearchCV(clf, param_grid=params, cv=kf, scoring='roc_auc').fit(x, y)\n",
    "clf = grid.best_estimator_\n",
    "\n",
    "cv = cross_val_score(clf, x, y, cv=kf, scoring='roc_auc')\n",
    "# Mean score: 0.619952716139\n",
    "print(clf, '\\n')\n",
    "print('Mean score:', cv.mean())\n",
    "print('Std Dev:   ', cv.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def absolute_correlations(col, df=data):\n",
    "    #absolute_values = np.abs(df[col])\n",
    "    corrs = pd.DataFrame(df.select_dtypes(include=[np.number]).corrwith(df[col]), columns=['correlation'])\n",
    "    corrs['absol'] = np.abs(corrs['correlation'])\n",
    "    return corrs.sort_values('absol', ascending=False).drop('absol', axis=1).tail(len(corrs)-1)\n",
    "\n",
    "absolute_correlations('target')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
